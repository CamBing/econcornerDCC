# And now you can do the following e.g.:
# rtn.final %>% filter(date %in% HighDates)
# RAMAPHOSA RALLY - defined as 11 Dec 2017 (cyclical high) to now.
# Ramaphosa sworn in on 15 Feb
# Zuma resigned 14 Feb
RRstartDate <- ymd(20171211)
# And now you can do the following
# rtn.final %>% filter(date >= RRstartDate)
#Regression approach
# Prep data ---------------------------------------------------------------
Regression_data <-
rtn.final #%>% select("date", "variable", "DlogReturn")
zar <-
Regression_data %>%  filter(variable == "ZAR") %>%
select("date", "DlogReturn") %>%
rename("usdzar_spot" = DlogReturn)
Regression_data <-
right_join(Regression_data, zar, by = "date") %>%
filter(variable != "ZAR") %>%
filter(!is.na(DlogReturn))
Regressions <-
Regression_data %>%
group_by(variable) %>%
do(reg = lm(usdzar_spot ~ (DlogReturn), data = .))
RegressionCoeffs <-
Regressions %>% tidy(reg)
#head(RegressionCoeffs)
# BEST HEDGES::
hedges <- RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., desc(estimate))
# Top 10 hedges::
top.10.reg <-
(RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., desc(estimate)))[1:10,]
# Rand Plays
worst.10.reg <-
(RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., estimate))[1:10,]
# Trimming the dataset ----------------------------------------------------
Pct_Valid <- 0.8 # This can change of course. 70% valid data over period at least
StartDate <- ymd(20031201)
EndDate <- ymd(20180404) #	2018-04-04
# Shorten timeframe
data <-
data %>% filter(date >= StartDate & date <= EndDate)
NDates <- length(unique(data %>% pull(date)) )
# Only used shares still active:
ActiveTickers <-
data %>%
filter(date >= ymd(20180404)) %>%
group_by(variable) %>%
mutate(N_Valid = ifelse(is.na(value) == TRUE, 0, 1)) %>%
summarise(S = sum(N_Valid)) %>%
filter(S >0) %>% pull(variable)
HoldTickers <-
data %>%
filter(variable %in% ActiveTickers) %>%
group_by(variable) %>%
mutate(N_Valid = ifelse(is.na(value) == TRUE, 0, 1) ) %>% summarise(N_Valid_Pct = sum(N_Valid)/NDates) %>%
filter(N_Valid_Pct >= Pct_Valid) %>% pull(variable) %>% unique()
rtn <-
data %>%
filter(variable %in% HoldTickers)
rtnseries <-
rtn %>% group_by(variable) %>%
mutate(Return = value/lag(value)-1)
rtnseries[is.na(rtnseries)] <- 0
rtnseries[is.infinite(rtnseries$value)] <- 0
rtn.final <-
rtnseries %>% arrange(date) %>% group_by(variable) %>% mutate(Return = coalesce(Return, 0)) %>%
mutate(Index = cumprod(1+Return) ) %>%
mutate(DlogReturn =  log(Index) - log( lag(Index))) %>% ungroup() %>%
mutate(DlogReturn = coalesce(DlogReturn, 0)) %>% select(-Index)
usdzar <-
rtn.final %>% filter(variable == "ZAR")
Df <-
usdzar %>% select(date, Return) %>% filter(date > first(date))
StratValue1 <- 0.2 # Change threshold
StratValue2 <- 0.8 # Change threshold
df_Strat <-
Df %>%
mutate(Q1 = quantile(Return, StratValue1, na.rm = TRUE), Q2 = quantile(Return, StratValue2, na.rm = TRUE)) %>%
mutate(ID = ifelse(Return <= Q1, "Low",
ifelse(Return > Q1 & Return <= Q2 , "Medium",
ifelse(Return > Q2 , "High", "NA")) )) %>% ungroup()
HighDates <- df_Strat %>% filter(ID == "High") %>% pull(date)
LowDates <- df_Strat %>% filter(ID == "Low") %>% pull(date)
RRstartDate <- ymd(20171211)
# And now you can do the following
#Regression approach
# Prep data ---------------------------------------------------------------
Regression_data <-
rtn.final #%>% select("date", "variable", "DlogReturn")
zar <-
Regression_data %>%  filter(variable == "ZAR") %>%
select("date", "DlogReturn") %>%
rename("usdzar_spot" = DlogReturn)
Regression_data <-
right_join(Regression_data, zar, by = "date") %>%
filter(variable != "ZAR") %>%
filter(!is.na(DlogReturn))
Regressions <-
Regression_data %>%
group_by(variable) %>%
do(reg = lm(usdzar_spot ~ (DlogReturn), data = .))
RegressionCoeffs <-
Regressions %>% tidy(reg)
#head(RegressionCoeffs)
# BEST HEDGES::
hedges <- RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., desc(estimate))
# Top 10 hedges::
top.10.reg <-
(RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., desc(estimate)))[1:10,]
# Rand Plays
worst.10.reg <-
(RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., estimate))[1:10,]
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(rmsfuns)
library(lubridate)
library(broom)
library(rugarch)
library(rmgarch)
library(tbl2xts)
# Load & Prep data --------------------------------------------------------
#NOTES:
# Make sure to remove NAs and weekends. -> No weekends in Yahoo finance data -> some not. See rows of NAs
# Drop stocks which haven't traded for long enough
#calculate returna
data <-
readRDS("data/data.rds")
# neat col names
colnames(data) <- gsub(x = colnames(data), pattern = ".JO.Adjusted|.X.Adjusted", replacement = "")
# Removing weekends & public holidays
data <-
data %>% xts_tbl() %>%
mutate(Days = format(date, "%A")) %>% filter(!Days %in% c("Saturday", "Sunday") ) %>% select(-Days)
data <-
data[!grepl("-12-25|-12-26|-01-01|-03-21|-03-30|-04-02|-04-27|-05-01|-06-16|-08-09|-09-24|-12-16|-12-17", data$date),]
# Long format
data <-
reshape2::melt(data, id="date", variable_name="symbol")
#****
# Trimming the dataset ----------------------------------------------------
Pct_Valid <- 0.8 # This can change of course. 70% valid data over period at least
StartDate <- ymd(20031201)
EndDate <- ymd(20180404) #	2018-04-04
# Shorten timeframe
data <-
data %>% filter(date >= StartDate & date <= EndDate)
NDates <- length(unique(data %>% pull(date)) )
# Only used shares still active:
ActiveTickers <-
data %>%
filter(date >= ymd(20180404)) %>%
group_by(variable) %>%
mutate(N_Valid = ifelse(is.na(value) == TRUE, 0, 1)) %>%
summarise(S = sum(N_Valid)) %>%
filter(S >0) %>% pull(variable)
HoldTickers <-
data %>%
filter(variable %in% ActiveTickers) %>%
group_by(variable) %>%
mutate(N_Valid = ifelse(is.na(value) == TRUE, 0, 1) ) %>% summarise(N_Valid_Pct = sum(N_Valid)/NDates) %>%
filter(N_Valid_Pct >= Pct_Valid) %>% pull(variable) %>% unique()
rtn <-
data %>%
filter(variable %in% HoldTickers | variable == "ZAR")
# Calculate returns -------------------------------------------------------
rtnseries <-
rtn %>% group_by(variable) %>%
mutate(Return = value/lag(value)-1)
rtnseries[is.na(rtnseries)] <- 0
rtnseries[is.infinite(rtnseries$value)] <- 0
#*** At this point it is in long format.. 4 cols: date, value, variable, Return (simple)
rtn.final <-
rtnseries %>% arrange(date) %>% group_by(variable) %>% mutate(Return = coalesce(Return, 0)) %>%
mutate(Index = cumprod(1+Return) ) %>%
mutate(DlogReturn =  log(Index) - log( lag(Index))) %>% ungroup() %>%
mutate(DlogReturn = coalesce(DlogReturn, 0)) %>% select(-Index)
#*** At this point it is in long format.. 5 cols: date, value, variable, Return (simple), DlogReturn
# Stratification ----------------------------------------------------------
# Stratify for high vol
# Ramaphosa rally
usdzar <-
rtn.final %>% filter(variable == "ZAR")
Df <-
usdzar %>% select(date, Return) %>% filter(date > first(date))
StratValue1 <- 0.2 # Change threshold
StratValue2 <- 0.8 # Change threshold
df_Strat <-
Df %>%
mutate(Q1 = quantile(Return, StratValue1, na.rm = TRUE), Q2 = quantile(Return, StratValue2, na.rm = TRUE)) %>%
mutate(ID = ifelse(Return <= Q1, "Low",
ifelse(Return > Q1 & Return <= Q2 , "Medium",
ifelse(Return > Q2 , "High", "NA")) )) %>% ungroup()
HighDates <- df_Strat %>% filter(ID == "High") %>% pull(date)
LowDates <- df_Strat %>% filter(ID == "Low") %>% pull(date)
# And now you can do the following e.g.:
# rtn.final %>% filter(date %in% HighDates)
# RAMAPHOSA RALLY - defined as 11 Dec 2017 (cyclical high) to now.
# Ramaphosa sworn in on 15 Feb
# Zuma resigned 14 Feb
RRstartDate <- ymd(20171211)
# And now you can do the following
# rtn.final %>% filter(date >= RRstartDate)
Regression_data <-
rtn.final #%>% select("date", "variable", "DlogReturn")
zar <-
Regression_data %>%  filter(variable == "ZAR") %>%
select("date", "DlogReturn") %>%
rename("usdzar_spot" = DlogReturn)
View(zar)
Regression_data <-
right_join(Regression_data, zar, by = "date") %>%
filter(variable != "ZAR") %>%
filter(!is.na(DlogReturn))
Regressions <-
Regression_data %>%
group_by(variable) %>%
do(reg = lm(usdzar_spot ~ (DlogReturn), data = .))
RegressionCoeffs <-
Regressions %>% tidy(reg)
#head(RegressionCoeffs)
# BEST HEDGES::
hedges <- RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., desc(estimate))
# Top 10 hedges::
top.10.reg <-
(RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., desc(estimate)))[1:10,]
# Rand Plays
worst.10.reg <-
(RegressionCoeffs %>%
filter(., term == "DlogReturn") %>%
select(., variable, estimate) %>%
arrange(., estimate))[1:10,]
View(top.10.reg)
View(worst.10.reg)
# DCC Approach
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(dplyr)
library(rmsfuns)
library(lubridate)
library(broom)
library(rugarch)
library(rmgarch)
library(tbl2xts)
library(MTS)
library(PerformanceAnalytics)
library(ggplot2)
library(ggthemes)
# Prep data ---------------------------------------------------------------
# Data must be in wide xts format
dcc.data <- rtn.final %>%
select(date, variable, DlogReturn) %>%
tbl_xts(., spread_by = "variable")
dcc.data.clean <- rtn.final %>%
select(date, variable, DlogReturn)
dcc.data.rtn <-
dcc.data.clean %>%
tbl_xts(., spread_by = "variable")
uspec <-
ugarchspec(variance.model = list(model = "gjrGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(1,0), include.mean = TRUE),
distribution.model = "sstd")
multi_univ_garch_spec <- multispec(replicate(ncol(dcc.data.rtn), uspec))
spec.dcc = dccspec(multi_univ_garch_spec,
dccOrder = c(1, 1),
distribution = 'mvnorm',
lag.criterion = c("AIC", "HQ", "SC", "FPE")[1],
model = c("DCC", "aDCC")[1])
cl = makePSOCKcluster(10)
# This takes a while to run (5 mins)
multf = multifit(multi_univ_garch_spec, dcc.data.rtn, cluster = cl)
fit.dcc = dccfit(spec.dcc,
data = dcc.data.rtn,
solver = 'solnp',
cluster = cl,
fit.control = list(eval.se = FALSE),
fit = multf)
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(rmsfuns)
library(lubridate)
library(broom)
library(rugarch)
library(rmgarch)
library(tbl2xts)
# Load & Prep data --------------------------------------------------------
#NOTES:
# Make sure to remove NAs and weekends. -> No weekends in Yahoo finance data -> some not. See rows of NAs
# Drop stocks which haven't traded for long enough
#calculate returna
data <-
readRDS("data/data.rds")
# neat col names
colnames(data) <- gsub(x = colnames(data), pattern = ".JO.Adjusted|.X.Adjusted", replacement = "")
# Removing weekends & public holidays
data <-
data %>% xts_tbl() %>%
mutate(Days = format(date, "%A")) %>% filter(!Days %in% c("Saturday", "Sunday") ) %>% select(-Days)
data <-
data[!grepl("-12-25|-12-26|-01-01|-03-21|-03-30|-04-02|-04-27|-05-01|-06-16|-08-09|-09-24|-12-16|-12-17", data$date),]
# Long format
data <-
reshape2::melt(data, id="date", variable_name="symbol")
#****
# Trimming the dataset ----------------------------------------------------
Pct_Valid <- 0 # This can change of course. 70% valid data over period at least
StartDate <- ymd(20031201)
EndDate <- ymd(20180404) #	2018-04-04
# Shorten timeframe
data <-
data %>% filter(date >= StartDate & date <= EndDate)
NDates <- length(unique(data %>% pull(date)) )
# Only used shares still active:
ActiveTickers <-
data %>%
filter(date >= ymd(20180404)) %>%
group_by(variable) %>%
mutate(N_Valid = ifelse(is.na(value) == TRUE, 0, 1)) %>%
summarise(S = sum(N_Valid)) %>%
filter(S >0) %>% pull(variable)
HoldTickers <-
data %>%
filter(variable %in% ActiveTickers) %>%
group_by(variable) %>%
mutate(N_Valid = ifelse(is.na(value) == TRUE, 0, 1) ) %>% summarise(N_Valid_Pct = sum(N_Valid)/NDates) %>%
filter(N_Valid_Pct >= Pct_Valid) %>% pull(variable) %>% unique()
rtn <-
data %>%
filter(variable %in% HoldTickers | variable == "ZAR")
# Calculate returns -------------------------------------------------------
rtnseries <-
rtn %>% group_by(variable) %>%
mutate(Return = value/lag(value)-1)
rtnseries[is.na(rtnseries)] <- 0
rtnseries[is.infinite(rtnseries$value)] <- 0
#*** At this point it is in long format.. 4 cols: date, value, variable, Return (simple)
rtn.final <-
rtnseries %>% arrange(date) %>% group_by(variable) %>% mutate(Return = coalesce(Return, 0)) %>%
mutate(Index = cumprod(1+Return) ) %>%
mutate(DlogReturn =  log(Index) - log( lag(Index))) %>% ungroup() %>%
mutate(DlogReturn = coalesce(DlogReturn, 0)) %>% select(-Index)
#*** At this point it is in long format.. 5 cols: date, value, variable, Return (simple), DlogReturn
# Stratification ----------------------------------------------------------
# Stratify for high vol
# Ramaphosa rally
usdzar <-
rtn.final %>% filter(variable == "ZAR")
Df <-
usdzar %>% select(date, Return) %>% filter(date > first(date))
StratValue1 <- 0.2 # Change threshold
StratValue2 <- 0.8 # Change threshold
df_Strat <-
Df %>%
mutate(Q1 = quantile(Return, StratValue1, na.rm = TRUE), Q2 = quantile(Return, StratValue2, na.rm = TRUE)) %>%
mutate(ID = ifelse(Return <= Q1, "Low",
ifelse(Return > Q1 & Return <= Q2 , "Medium",
ifelse(Return > Q2 , "High", "NA")) )) %>% ungroup()
HighDates <- df_Strat %>% filter(ID == "High") %>% pull(date)
LowDates <- df_Strat %>% filter(ID == "Low") %>% pull(date)
# And now you can do the following e.g.:
# rtn.final %>% filter(date %in% HighDates)
# RAMAPHOSA RALLY - defined as 11 Dec 2017 (cyclical high) to now.
# Ramaphosa sworn in on 15 Feb
# Zuma resigned 14 Feb
RRstartDate <- ymd(20171211)
# And now you can do the following
# rtn.final %>% filter(date >= RRstartDate)
# DCC Approach
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(dplyr)
library(rmsfuns)
library(lubridate)
library(broom)
library(rugarch)
library(rmgarch)
library(tbl2xts)
library(MTS)
library(PerformanceAnalytics)
library(ggplot2)
library(ggthemes)
# Prep data ---------------------------------------------------------------
# Data must be in wide xts format
dcc.data <- rtn.final %>%
select(date, variable, DlogReturn) %>%
tbl_xts(., spread_by = "variable")
dcc.data.clean <- rtn.final %>%
select(date, variable, DlogReturn)
# Trimming dataset --------------------------------------------------------
Pct_Valid <- 0.9 # works with 0.9 # This can change of course. 70% valid data over period at least
NDates.dcc <- length(unique(dcc.data.clean %>% pull(date)) )
HoldTickers.dcc <-
dcc.data.clean %>%
group_by(variable) %>%
mutate(N_Valid = ifelse(DlogReturn == 0, 0, 1) ) %>% summarise(N_Valid_Pct = sum(N_Valid)/NDates.dcc) %>%
filter(N_Valid_Pct >= Pct_Valid) %>% pull(variable) %>% unique()
dcc.data.rtn <-
dcc.data.clean %>%
filter(variable %in% HoldTickers.dcc | variable == "ZAR") %>%
tbl_xts(., spread_by = "variable")
# Build DCC ---------------------------------------------------------------
# NOTE: data needs to be in wide format (tbl_xts() works)
uspec <-
ugarchspec(variance.model = list(model = "gjrGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(1,0), include.mean = TRUE),
distribution.model = "sstd")
multi_univ_garch_spec <- multispec(replicate(ncol(dcc.data.rtn), uspec))
spec.dcc = dccspec(multi_univ_garch_spec,
dccOrder = c(1, 1),
distribution = 'mvnorm',
lag.criterion = c("AIC", "HQ", "SC", "FPE")[1],
model = c("DCC", "aDCC")[1])
cl = makePSOCKcluster(10)
# This takes a while to run (5 mins)
multf = multifit(multi_univ_garch_spec, dcc.data.rtn, cluster = cl)
fit.dcc = dccfit(spec.dcc,
data = dcc.data.rtn,
solver = 'solnp',
cluster = cl,
fit.control = list(eval.se = FALSE),
fit = multf)
# We can now test the model's fit as follows:
#   Let's use the covariance matrices to test the adequacy of MV model in fitting mean residual processes:
RcovList <- rcov(fit.dcc) # This is now a list of the monthly covariances of our DCC model series.
covmat = matrix(RcovList,nrow(dcc.data.rtn),ncol(dcc.data.rtn)*ncol(dcc.data.rtn),byrow=TRUE)
mc1 = MTS::MCHdiag(dcc.data.rtn,covmat) # NEED TO INTERPRET RESULTS OF TEST
dcc.time.var.cor <- rcor(fit.dcc)
#print(dcc.time.var.cor)
# Plotting
dcc.time.var.cor <- aperm(dcc.time.var.cor,c(3,2,1))
dim(dcc.time.var.cor) <- c(nrow(dcc.time.var.cor), ncol(dcc.time.var.cor)^2)
# Renaming function ====
renamingdcc <- function(ReturnSeries, DCC.TV.Cor) {
ncolrtn <- ncol(ReturnSeries)
namesrtn <- colnames(ReturnSeries)
paste(namesrtn, collapse = "_")
nam <- c()
xx <- mapply(rep, times = ncolrtn:1, x = namesrtn)
nam <- c()
for (j in 1:(ncolrtn)) {
for (i in 1:(ncolrtn)) {
nam[(i + (j-1)*(ncolrtn))] <- paste(xx[[j]][1], xx[[i]][1], sep="_")
}
}
colnames(DCC.TV.Cor) <- nam
# So to plot all the time-varying correlations wrt SBK:
# First append the date column that has (again) been removed...
DCC.TV.Cor <-
data.frame( cbind( date = index(ReturnSeries), DCC.TV.Cor)) %>% # Add date column which dropped away...
mutate(date = as.Date(date)) %>%  tbl_df()
DCC.TV.Cor <- DCC.TV.Cor %>% gather(Pairs, Rho, -date)
DCC.TV.Cor
}
#end of function
dcc.time.var.cor <-
renamingdcc(ReturnSeries = dcc.data.rtn, DCC.TV.Cor = dcc.time.var.cor)
all.correl <-
ggplot(dcc.time.var.cor %>% filter(grepl("ZAR_", Pairs ), !grepl("_ZAR", Pairs)) ) +
geom_line(aes(x = date, y = Rho, colour = Pairs)) +
theme_hc() +
ggtitle("Dynamic Conditional Correlations: ZAR")
all.correl
#=== === === ===
# Top 10 graph
#=== === === ===
# Top 10 by average Rho
zarDCC <- dcc.time.var.cor %>% filter(grepl("ZAR_", Pairs ), !grepl("_ZAR", Pairs))
top.10.reg.list.avg <-
(zarDCC %>% group_by(Pairs) %>%
summarise(avg = mean(Rho)) %>%
arrange(., desc(avg)))[1:10,]
top.10.graph.avg <- zarDCC %>% filter(Pairs %in% c(top.10.reg.list.avg$Pairs)) %>%
ggplot( ) +
geom_line(aes(x = date, y = Rho, colour = Pairs)) +
theme_hc() +
ggtitle("Top 10 Dynamic Conditional Correlations: ZAR")
top.10.graph.avg
#From regression approach
top.10.reg.list <- top.10.reg[,1]
top.10.reg.list$variable <- paste0('ZAR_', top.10.reg.list$variable)
colnames(top.10.reg.list) <- "Pairs"
#top.10.reg.list <- top.10.reg.list$Pairs
top.10.graph <- zarDCC %>% filter(Pairs %in% top.10.reg.list$Pairs) %>%
ggplot( ) +
geom_line(aes(x = date, y = Rho, colour = Pairs)) +
theme_hc() +
ggtitle("Top 10 Dynamic Conditional Correlations: ZAR")
top.10.graph
